{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7ba93-e16b-4430-bd78-8c34ebd052ae",
   "metadata": {},
   "source": [
    "# Time-series forecasting - Lap records in Formula 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304c975-67e4-418d-af82-ea5862c9902d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this step, it mainly wants to show the use of trained model to forecast. The purpose is to follow the pattern/steps of machine learning pipeline.\n",
    "\n",
    "Machine Learning (ML) Pipeline automates the workflow it takes to produce a machine learning model, and it consists of multiple sequential steps that do everything from data extraction, preprocessing and feature engineering to model training and deployment. Usuually, it covers from development to deployment in an automated manner.\n",
    "\n",
    "The diagram demonstrates the experimental workflow (without MLOps) in this exercise:\n",
    "\n",
    "<img src=\"../pictures/machine-learning-pipeline.png\" width=\"800\">\n",
    "\n",
    "Essentially, in this machine learning workflow, the model is the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b075a442-4e0b-4197-896d-656ef3107720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ipywidgets import widgets, interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88544c96-ad62-4be7-ad41-1972b966e1dc",
   "metadata": {},
   "source": [
    "## Loading pre-trained ML model \n",
    "\n",
    "The trained model in the previous step was saved into _pickle_ file, so loads it by using _pickle_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a759a8e3-71cb-482f-8646-7a2abfa9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/05-trained-models/rf-trained-model.pkl', 'rb') as f:\n",
    "    rf_regressor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f876f564-8895-43f2-8d32-e5994d97fbef",
   "metadata": {},
   "source": [
    "## Loading the testing files for predication\n",
    "\n",
    "Testing data is used for validation and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cce0e2ef-b9b2-48ba-8af4-ca40d9b607a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182075, 4)\n",
      "(182075, 1)\n"
     ]
    }
   ],
   "source": [
    "df_test_features = pd.read_csv('../data/04-train-test-data/test_data.csv')\n",
    "df_test_labels = pd.read_csv('../data/04-train-test-data/test_labels.csv')\n",
    "print(df_test_features.shape)\n",
    "print(df_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dca8c11a-6ccc-4e37-a475-4a5248255131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.01311000e+05, 9.46555962e+04, 8.97570000e+01]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df_test_features.values\n",
    "y_test = df_test_labels.values\n",
    "X_test[99:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2dcd4cbc-9c39-4fab-89c7-49b60b3b5e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182075, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16, 'Japanese Grand Prix']], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_ident = pd.read_csv('../data/04-train-test-data/pred_ident.csv')\n",
    "lap_identifier = df_pred_ident.values\n",
    "print(lap_identifier.shape)\n",
    "lap_identifier[88666:88667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19365718-4ffe-43c0-8d69-4f93c923e709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20, 'Australian Grand Prix', 82736.0]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_pred = np.column_stack((lap_identifier, lt_pred))\n",
    "np_pred[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef67050-3bf6-47cc-a5d1-f70f9b49c190",
   "metadata": {},
   "source": [
    "## Forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "764e1602-5ea2-479a-a2e3-147f684c7e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182075,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_pred = rf_regressor.predict(X_test)\n",
    "lt_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72b4e9cf-70ec-4c7f-bc0c-5db69de3f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(lt_pred)\n",
    "df_pred.to_csv('../data/06-inferences/pred_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddb705-6ddb-4bdd-86bc-76f6eec0ac05",
   "metadata": {},
   "source": [
    "## Further forcasting\n",
    "\n",
    "If want to predict further with the speficic driver and event, we can prepare some data and follow the above way to predict/forecast.\n",
    "\n",
    "Sample data:\n",
    "\n",
    "[16, 'Japanese Grand Prix', 1, 10368, 9812, 8139]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af589b-9980-49db-86b4-f30ca701d63c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this exercise, manual steps are mainly taken for the experimental and exploratory purpose. \n",
    "\n",
    "Once the experiment and development stage is finalized, the framework of MLOps (Machine Learning Operations) is recommended to use for the whole AI/ML project as the guidance to develop, deploy and monitor, etc.\n",
    "\n",
    "Machine learning operations (MLOps) are a set of practices that automate and simplify machine learning (ML) workflows and deployments. We can use MLOps to automate and standardize processes across the ML lifecycle. These processes include model development, testing, integration, release, and infrastructure management.\n",
    "\n",
    "MLOps is critical to systematically and simultaneously manage the release of new ML models with application code and data changes. The ML assets will be treated similarly to other continuous integration and delivery (CI/CD) environment software assets. The following diagram shows the automated MLOps lifecycle for reference. \n",
    "\n",
    "<img src=\"../pictures/mlops.png\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0085d4e-135b-4056-bc0c-e442f22046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
